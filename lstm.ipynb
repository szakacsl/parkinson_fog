{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Long Short-Term Memory to detect and classify Parkinsons' Freezing of Gait types in time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\hurub\\.julia\\environments\\v1.8\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\hurub\\.julia\\environments\\v1.8\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.add(\"NNlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: @epochs, batch, throttle\n",
    "\n",
    "using NNlib\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct LongShortTermMemory\n",
    "    input_size::Int\n",
    "    outpus_size::Int\n",
    "\n",
    "    # trainable parameters of the model\n",
    "    Wf::AbstractMatrix # params of the Forget Gate\n",
    "    Wi::AbstractMatrix # params of the Input Gate\n",
    "    Wc::AbstractMatrix # params of the Input Modulation Gate\n",
    "    Wo::AbstractMatrix # params of the Output Gate\n",
    "\n",
    "    # biases of the Gates above\n",
    "    bf::AbstractVector\n",
    "    bi::AbstractVector\n",
    "    bc::AbstractVector\n",
    "    bo::AbstractVector\n",
    "\n",
    "    # cell state (aka. long-term memory) and hidden state (aka. short-term memory)\n",
    "    c::AbstractVector\n",
    "    h::AbstractVector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize weights with Gaussian distribution\n",
    "function LSTM(input_size::Int, hidden_size::Int ; mean=0.0, std=1.0)\n",
    "    LongShortTermMemory(\n",
    "        input_size, hidden_size,\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)), # Wf\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)), # Wi\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)), # Wc\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)), # Wo\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), hidden_size), # bf\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), hidden_size), # bi\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), hidden_size), # bc\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), hidden_size), # bo\n",
    "\n",
    "        # both the Long-Term and Short-Term memories are initialized with 0 values\n",
    "        zeros(hidden_size), # c\n",
    "        zeros(hidden_size)  # h\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 2 methods)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing the forwarding method which is used in the Chaining process\n",
    "function forward(lstm::LongShortTermMemory, x)\n",
    "    # calculating the Memory modifier values\n",
    "    f = NNlib.sigmoid_fast(lstm.Wf * x .+ bf) #\n",
    "    i = NNlib.sigmoid_fast(lstm.Wi * x .+ bi) #\n",
    "    o = NNlib.sigmoid_fast(lstm.Wo * x .+ bo) #\n",
    "\n",
    "    # calculating the new memory values\n",
    "    c = f .* lstm.c .+ i .* NNlib.tanh_fast(lstm.Wc * x .+ bc) # new Long-Term Memory\n",
    "    h = o .* NNlib.tanh_fast(c) # new Short-Term Memory\n",
    "\n",
    "    # updating the memory\n",
    "    lstm.c, lstm.h = c, h\n",
    "\n",
    "    # returning the hidden parameters for the next layer\n",
    "    h\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  LongShortTermMemory(10, 20, [0.8187270247953213 0.7437034558082871 … 0.5310576341451857 0.06948511553957118; 0.034388594760129086 0.11011203219259434 … 0.288478060833857 0.20468429534807608; … ; 0.387241047879294 0.7043523564329524 … 0.6646817527348291 0.012376889571117487; 0.44548252714645115 0.4349887693590795 … 0.478296895433531 0.4651957903613904], [0.8887420527669128 0.3226724154627717 … 0.5274955422071969 0.5827336741777697; 0.3421683838843972 0.04633976373134851 … 0.5830183866134266 0.7826051437997072; … ; 0.7825930260759104 0.5396772746779909 … 0.3430953836507762 0.8963115270243956; 0.4636154379426843 0.16701884828094463 … 0.08743218033467748 0.17897025841980793], [0.5173363612812469 0.36256385478911773 … 0.20154640672784077 0.9282548305954437; 0.18164247067614844 0.4720692656705815 … 0.5135633308785238 0.1695685770625405; … ; 0.12370324873578749 0.12475463178568412 … 0.1499922790253042 0.267038611359769; 0.1872758382876212 0.048394715150974446 … 0.35875837645735037 0.3578979038186581], [0.3139594587020639 0.32918721475260265 … 0.3027818933694057 0.29004566447126406; 0.9178895098575814 0.07622483463598805 … 0.9975799242574376 0.01807482618918544; … ; 0.14615482569214766 0.6071741368659996 … 0.11423150873130222 0.0439448586852149; 0.6892493935804719 0.9550751654005208 … 0.06689556020559141 0.3392501129286023], [0.5635109368073237, 0.07679079049894227, 0.15186723693202092, 0.11201865400684603, 0.9223549825585011, 0.7502694548391523, 0.3664753119661567, 0.8986022527358096, 0.020778071467107122, 0.971139654969936, 0.5974568663049612, 0.603116794691466, 0.3081767439802475, 0.5184474147014515, 0.025121521348114243, 0.6052431567784872, 0.5079362243190068, 0.9242919576538324, 0.6460355106235488, 0.18678172870172072], [0.16838227065441452, 0.42497148413549957, 0.07550552913358431, 0.8533655683406337, 0.1784465931806242, 0.30090192099950214, 0.7570445607259827, 0.9347750357566111, 0.7901109216897588, 0.07331153894010763, 0.0366141426027231, 0.10010789820666706, 0.7089045983202491, 0.15335650267543047, 0.3528900326098024, 0.43005701970893623, 0.030206018689262863, 0.9465618813945742, 0.10560568799555338, 0.036207123887625675], [0.6468972233658881, 0.20375679434002633, 0.4352073397996533, 0.6447623081183637, 0.3999806404093373, 0.15939025081493013, 0.3127913328847948, 0.8292463881910639, 0.001736216722949195, 0.18063149596854197, 0.1086055639147798, 0.6634208225826411, 0.5887067125087015, 0.5179441957197354, 0.8469988611710013, 0.1509124598615198, 0.08689741406988666, 0.697105981803631, 0.666675868154879, 0.8580846454560179], [0.233505728975673, 0.8896667406309073, 0.5422293285953205, 0.9633354147286911, 0.4254115772943151, 0.43859475877944337, 0.25554064387270387, 0.7306582058011973, 0.3913789804586729, 0.6863865143399704, 0.8051257354953381, 0.298933677271853, 0.7362857873375899, 0.5550665835349469, 0.21755728222731677, 0.5180004673646456, 0.6219549972906436, 0.8971111563271726, 0.2424417463032346, 0.32640006384803866], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       "  Dense(20 => 4),                       \u001b[90m# 84 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_classes = 4 \n",
    "\n",
    "model = Chain(\n",
    "    LSTM(input_size, hidden_size),\n",
    "    Dense(hidden_size, num_classes),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.crossentropy(model(x), y)\n",
    "optimizer = ADAM(0.001)\n",
    "epochs = 10\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: your_data_iterator not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: your_data_iterator not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[73]:2"
     ]
    }
   ],
   "source": [
    "for epoch in 1:epochs\n",
    "  for (input, output) in your_data_iterator\n",
    "    grads = Flux.gradient(params(model)) do\n",
    "      loss(input, output)\n",
    "    end\n",
    "    Flux.update!(optimizer, params(model), grads)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
