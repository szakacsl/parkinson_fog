{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Long Short-Term Memory to detect and classify Parkinsons' Freezing of Gait types in time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "# Pkg.add(\"CSV\")\n",
    "# Pkg.add(\"NNlib\")\n",
    "# Pkg.add(\"DataFrames\")\n",
    "# Pkg.add(\"Distributions\")\n",
    "# Pkg.add(\"ResumableFunctions\")\n",
    "# Pkg.add(\"Flux\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: @epochs, batch, throttle\n",
    "\n",
    "using CSV\n",
    "using BSON: @save, @load\n",
    "using Plots\n",
    "using NNlib\n",
    "using Random\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using ResumableFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>525804×13 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">525779 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Id</th><th style = \"text-align: left;\">Subject</th><th style = \"text-align: left;\">Visit</th><th style = \"text-align: left;\">Test</th><th style = \"text-align: left;\">Medication</th><th style = \"text-align: left;\">Time</th><th style = \"text-align: left;\">AccV</th><th style = \"text-align: left;\">AccML</th><th style = \"text-align: left;\">AccAP</th><th style = \"text-align: left;\">StartHesitation</th><th style = \"text-align: left;\">Turn</th><th style = \"text-align: left;\">Walking</th><th style = \"text-align: left;\">event</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String7\" style = \"text-align: left;\">String7</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">-9.4173</td><td style = \"text-align: right;\">0.767819</td><td style = \"text-align: right;\">-1.75824</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-9.4251</td><td style = \"text-align: right;\">0.768246</td><td style = \"text-align: right;\">-1.75058</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">-9.41995</td><td style = \"text-align: right;\">0.779039</td><td style = \"text-align: right;\">-1.74259</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">-9.42127</td><td style = \"text-align: right;\">0.772523</td><td style = \"text-align: right;\">-1.74651</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">-9.42811</td><td style = \"text-align: right;\">0.777142</td><td style = \"text-align: right;\">-1.75555</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-9.42602</td><td style = \"text-align: right;\">0.774812</td><td style = \"text-align: right;\">-1.76021</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-9.42569</td><td style = \"text-align: right;\">0.768126</td><td style = \"text-align: right;\">-1.7736</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">-9.43509</td><td style = \"text-align: right;\">0.765923</td><td style = \"text-align: right;\">-1.76937</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">-9.43209</td><td style = \"text-align: right;\">0.770584</td><td style = \"text-align: right;\">-1.77557</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">-9.4295</td><td style = \"text-align: right;\">0.775137</td><td style = \"text-align: right;\">-1.77076</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">-9.41142</td><td style = \"text-align: right;\">0.772588</td><td style = \"text-align: right;\">-1.76626</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">-9.42808</td><td style = \"text-align: right;\">0.774885</td><td style = \"text-align: right;\">-1.74877</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">009ee11563</td><td style = \"text-align: left;\">f62eec</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2</td><td style = \"text-align: left;\">on</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">-9.4235</td><td style = \"text-align: right;\">0.770305</td><td style = \"text-align: right;\">-1.74199</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525793</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6453</td><td style = \"text-align: right;\">-9.53302</td><td style = \"text-align: right;\">0.579309</td><td style = \"text-align: right;\">-1.04424</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525794</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6454</td><td style = \"text-align: right;\">-9.52948</td><td style = \"text-align: right;\">0.592304</td><td style = \"text-align: right;\">-1.05148</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525795</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6455</td><td style = \"text-align: right;\">-9.52566</td><td style = \"text-align: right;\">0.58729</td><td style = \"text-align: right;\">-1.0361</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525796</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6456</td><td style = \"text-align: right;\">-9.52386</td><td style = \"text-align: right;\">0.570158</td><td style = \"text-align: right;\">-1.03295</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525797</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6457</td><td style = \"text-align: right;\">-9.52654</td><td style = \"text-align: right;\">0.565428</td><td style = \"text-align: right;\">-1.04679</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525798</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6458</td><td style = \"text-align: right;\">-9.52059</td><td style = \"text-align: right;\">0.585287</td><td style = \"text-align: right;\">-1.06743</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525799</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6459</td><td style = \"text-align: right;\">-9.52391</td><td style = \"text-align: right;\">0.574692</td><td style = \"text-align: right;\">-1.06909</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525800</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6460</td><td style = \"text-align: right;\">-9.52473</td><td style = \"text-align: right;\">0.578778</td><td style = \"text-align: right;\">-1.08534</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525801</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6461</td><td style = \"text-align: right;\">-9.52702</td><td style = \"text-align: right;\">0.58106</td><td style = \"text-align: right;\">-1.08309</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525802</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6462</td><td style = \"text-align: right;\">-9.53587</td><td style = \"text-align: right;\">0.585846</td><td style = \"text-align: right;\">-1.08294</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525803</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6463</td><td style = \"text-align: right;\">-9.52958</td><td style = \"text-align: right;\">0.583186</td><td style = \"text-align: right;\">-1.06742</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">525804</td><td style = \"text-align: left;\">fb14eb4a33</td><td style = \"text-align: left;\">4ca9b3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: left;\">off</td><td style = \"text-align: right;\">6464</td><td style = \"text-align: right;\">-9.53342</td><td style = \"text-align: right;\">0.588161</td><td style = \"text-align: right;\">-1.04666</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Normal</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& Id & Subject & Visit & Test & Medication & Time & AccV & AccML & AccAP & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String7 & Int64 & Int64 & String3 & Int64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 009ee11563 & f62eec & 4 & 2 & on & 0 & -9.4173 & 0.767819 & -1.75824 & $\\dots$ \\\\\n",
       "\t2 & 009ee11563 & f62eec & 4 & 2 & on & 1 & -9.4251 & 0.768246 & -1.75058 & $\\dots$ \\\\\n",
       "\t3 & 009ee11563 & f62eec & 4 & 2 & on & 2 & -9.41995 & 0.779039 & -1.74259 & $\\dots$ \\\\\n",
       "\t4 & 009ee11563 & f62eec & 4 & 2 & on & 3 & -9.42127 & 0.772523 & -1.74651 & $\\dots$ \\\\\n",
       "\t5 & 009ee11563 & f62eec & 4 & 2 & on & 4 & -9.42811 & 0.777142 & -1.75555 & $\\dots$ \\\\\n",
       "\t6 & 009ee11563 & f62eec & 4 & 2 & on & 5 & -9.42602 & 0.774812 & -1.76021 & $\\dots$ \\\\\n",
       "\t7 & 009ee11563 & f62eec & 4 & 2 & on & 6 & -9.42569 & 0.768126 & -1.7736 & $\\dots$ \\\\\n",
       "\t8 & 009ee11563 & f62eec & 4 & 2 & on & 7 & -9.43509 & 0.765923 & -1.76937 & $\\dots$ \\\\\n",
       "\t9 & 009ee11563 & f62eec & 4 & 2 & on & 8 & -9.43209 & 0.770584 & -1.77557 & $\\dots$ \\\\\n",
       "\t10 & 009ee11563 & f62eec & 4 & 2 & on & 9 & -9.4295 & 0.775137 & -1.77076 & $\\dots$ \\\\\n",
       "\t11 & 009ee11563 & f62eec & 4 & 2 & on & 10 & -9.41142 & 0.772588 & -1.76626 & $\\dots$ \\\\\n",
       "\t12 & 009ee11563 & f62eec & 4 & 2 & on & 11 & -9.42808 & 0.774885 & -1.74877 & $\\dots$ \\\\\n",
       "\t13 & 009ee11563 & f62eec & 4 & 2 & on & 12 & -9.4235 & 0.770305 & -1.74199 & $\\dots$ \\\\\n",
       "\t14 & 009ee11563 & f62eec & 4 & 2 & on & 13 & -9.41724 & 0.776865 & -1.7581 & $\\dots$ \\\\\n",
       "\t15 & 009ee11563 & f62eec & 4 & 2 & on & 14 & -9.41857 & 0.770342 & -1.75525 & $\\dots$ \\\\\n",
       "\t16 & 009ee11563 & f62eec & 4 & 2 & on & 15 & -9.41036 & 0.770009 & -1.76036 & $\\dots$ \\\\\n",
       "\t17 & 009ee11563 & f62eec & 4 & 2 & on & 16 & -9.42579 & 0.76133 & -1.77374 & $\\dots$ \\\\\n",
       "\t18 & 009ee11563 & f62eec & 4 & 2 & on & 17 & -9.42563 & 0.763608 & -1.75553 & $\\dots$ \\\\\n",
       "\t19 & 009ee11563 & f62eec & 4 & 2 & on & 18 & -9.42325 & 0.768116 & -1.75313 & $\\dots$ \\\\\n",
       "\t20 & 009ee11563 & f62eec & 4 & 2 & on & 19 & -9.42427 & 0.76787 & -1.74709 & $\\dots$ \\\\\n",
       "\t21 & 009ee11563 & f62eec & 4 & 2 & on & 20 & -9.43068 & 0.783869 & -1.74666 & $\\dots$ \\\\\n",
       "\t22 & 009ee11563 & f62eec & 4 & 2 & on & 21 & -9.42091 & 0.788434 & -1.76641 & $\\dots$ \\\\\n",
       "\t23 & 009ee11563 & f62eec & 4 & 2 & on & 22 & -9.40773 & 0.772329 & -1.77136 & $\\dots$ \\\\\n",
       "\t24 & 009ee11563 & f62eec & 4 & 2 & on & 23 & -9.41443 & 0.781489 & -1.77574 & $\\dots$ \\\\\n",
       "\t25 & 009ee11563 & f62eec & 4 & 2 & on & 24 & -9.4354 & 0.772634 & -1.77856 & $\\dots$ \\\\\n",
       "\t26 & 009ee11563 & f62eec & 4 & 2 & on & 25 & -9.43418 & 0.772913 & -1.7709 & $\\dots$ \\\\\n",
       "\t27 & 009ee11563 & f62eec & 4 & 2 & on & 26 & -9.43279 & 0.763644 & -1.77615 & $\\dots$ \\\\\n",
       "\t28 & 009ee11563 & f62eec & 4 & 2 & on & 27 & -9.41411 & 0.749968 & -1.79392 & $\\dots$ \\\\\n",
       "\t29 & 009ee11563 & f62eec & 4 & 2 & on & 28 & -9.41413 & 0.763503 & -1.78475 & $\\dots$ \\\\\n",
       "\t30 & 009ee11563 & f62eec & 4 & 2 & on & 29 & -9.4102 & 0.761039 & -1.78745 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m525804×13 DataFrame\u001b[0m\n",
       "\u001b[1m    Row \u001b[0m│\u001b[1m Id         \u001b[0m\u001b[1m Subject \u001b[0m\u001b[1m Visit \u001b[0m\u001b[1m Test  \u001b[0m\u001b[1m Medication \u001b[0m\u001b[1m Time  \u001b[0m\u001b[1m AccV     \u001b[0m\u001b[1m AccM\u001b[0m ⋯\n",
       "        │\u001b[90m String15   \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m String3    \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "────────┼───────────────────────────────────────────────────────────────────────\n",
       "      1 │ 009ee11563  f62eec       4      2  on              0  -9.4173   0.76 ⋯\n",
       "      2 │ 009ee11563  f62eec       4      2  on              1  -9.4251   0.76\n",
       "      3 │ 009ee11563  f62eec       4      2  on              2  -9.41995  0.77\n",
       "      4 │ 009ee11563  f62eec       4      2  on              3  -9.42127  0.77\n",
       "      5 │ 009ee11563  f62eec       4      2  on              4  -9.42811  0.77 ⋯\n",
       "      6 │ 009ee11563  f62eec       4      2  on              5  -9.42602  0.77\n",
       "      7 │ 009ee11563  f62eec       4      2  on              6  -9.42569  0.76\n",
       "      8 │ 009ee11563  f62eec       4      2  on              7  -9.43509  0.76\n",
       "      9 │ 009ee11563  f62eec       4      2  on              8  -9.43209  0.77 ⋯\n",
       "     10 │ 009ee11563  f62eec       4      2  on              9  -9.4295   0.77\n",
       "     11 │ 009ee11563  f62eec       4      2  on             10  -9.41142  0.77\n",
       "   ⋮    │     ⋮          ⋮       ⋮      ⋮        ⋮         ⋮       ⋮         ⋮ ⋱\n",
       " 525795 │ fb14eb4a33  4ca9b3       2      1  off          6455  -9.52566  0.58\n",
       " 525796 │ fb14eb4a33  4ca9b3       2      1  off          6456  -9.52386  0.57 ⋯\n",
       " 525797 │ fb14eb4a33  4ca9b3       2      1  off          6457  -9.52654  0.56\n",
       " 525798 │ fb14eb4a33  4ca9b3       2      1  off          6458  -9.52059  0.58\n",
       " 525799 │ fb14eb4a33  4ca9b3       2      1  off          6459  -9.52391  0.57\n",
       " 525800 │ fb14eb4a33  4ca9b3       2      1  off          6460  -9.52473  0.57 ⋯\n",
       " 525801 │ fb14eb4a33  4ca9b3       2      1  off          6461  -9.52702  0.58\n",
       " 525802 │ fb14eb4a33  4ca9b3       2      1  off          6462  -9.53587  0.58\n",
       " 525803 │ fb14eb4a33  4ca9b3       2      1  off          6463  -9.52958  0.58\n",
       " 525804 │ fb14eb4a33  4ca9b3       2      1  off          6464  -9.53342  0.58 ⋯\n",
       "\u001b[36m                                               6 columns and 525783 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkinson_train = CSV.read(\"./filtered_data.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_loader (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@resumable function train_loader(train_dataframe, num_sequences, num_selected_sequences, batch_size; labels=[\"StartHesitation\", \"Turn\", \"Walking\", \"Normal\"])\n",
    "    @assert num_selected_sequences <= num_sequences\n",
    "    \n",
    "    tdf = deepcopy(train_dataframe)\n",
    "    \n",
    "    sequences = collect(1:num_sequences)\n",
    "    shuffle!(sequences)\n",
    "\n",
    "    # Sending to the model\n",
    "    for i in 1:num_selected_sequences\n",
    "        # if benne van a random generalt elemek tombunkben\n",
    "        x = hcat(\n",
    "            tdf[!, \"AccV\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size],\n",
    "            tdf[!, \"AccML\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size],\n",
    "            tdf[!, \"AccAP\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size]\n",
    "        )\n",
    "    \n",
    "        y = Flux.onehotbatch(tdf[!, \"event\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size], labels)\n",
    "        \n",
    "        @yield x, y\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@resumable function validation_loader(validation_dataframe, num_sequences, num_selected_sequences, batch_size; labels=[\"StartHesitation\", \"Turn\", \"Walking\", \"Normal\"])\n",
    "    @assert num_selected_sequences <= num_sequences\n",
    "    \n",
    "    vdf = deepcopy(validation_dataframe)\n",
    "    \n",
    "    sequences = collect(1:num_sequences)\n",
    "    shuffle!(sequences)\n",
    "\n",
    "    # Sending to the model\n",
    "    for i in 1:num_selected_sequences\n",
    "        # if benne van a random generalt elemek tombunkben\n",
    "        x = hcat(\n",
    "            vdf[!, \"AccV\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size],\n",
    "            vdf[!, \"AccML\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size],\n",
    "            vdf[!, \"AccAP\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size]\n",
    "        )\n",
    "    \n",
    "        y = Flux.onehotbatch(vdf[!, \"event\"][sequences[i] * batch_size : sequences[i] * batch_size + batch_size], labels)\n",
    "        \n",
    "        @yield x, y\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_params (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_params(in::Integer, out::Integer; mean=0.0, std=1.0)\n",
    "    [\n",
    "        in, out,\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # Wf\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # Wi\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # Wc\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # Wo\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bf\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bi\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bc\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bo\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bo\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bo\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bo\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bo\n",
    "\n",
    "        # both the Long-Term and Short-Term memories are initialized with 0 values\n",
    "        zeros(out),  # c\n",
    "        zeros(out),  # h\n",
    "        true # update_memory\n",
    "    ]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing the forwarding method which is used in the Chaining process\n",
    "function forward(x, lstm)\n",
    "\n",
    "    for i in 1:size(x, 1)\n",
    "        long_remember_percent = NNlib.sigmoid_fast((lstm.c .* lstm.wlr1) + (x[i, :] .* lstm.wlr2) + lstm.blr1)\n",
    "        potential_remember_percent = NNlib.sigmoid_fast((lstm.h .* lstm.wpr1) + (x[i, :] .* lstm.wpr2) + lstm.bpr1)\n",
    "        potential_memory = NNlib.tanh_fast((lstm.c .* lstm.wp1) + (x[i, :] .* lstm.wp2) + lstm.bp1)\n",
    "        updated_long_memory = (lstm.c .* long_remember_percent) + (potential_memory .* potential_remember_percent)\n",
    "        output_percent = NNlib.sigmoid_fast((lstm.h .* lstm.wo1) + (x[i, :] .* lstm.wo2) + lstm.bo1)\n",
    "        updated_short_memory = NNlib.tanh_fast(updated_long_memory) .* output_percent\n",
    "\n",
    "        # updating the memory\n",
    "        if lstm.update_memory\n",
    "            lstm.c, lstm.h = updated_long_memory, updated_short_memory\n",
    "        end\n",
    "    end\n",
    "\n",
    "    lstm.c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom Long Short-Term Memory layer\n",
    "mutable struct LSTM\n",
    "    # input and output size of the layer\n",
    "    in::Integer\n",
    "    out::Integer\n",
    "\n",
    "    wlr1::Vector{Float32}\n",
    "    wlr2::Vector{Float32}\n",
    "    blr1::Vector{Float32}\n",
    "\n",
    "    wpr1::Vector{Float32}\n",
    "    wpr2::Vector{Float32}\n",
    "    bpr1::Vector{Float32}\n",
    "\n",
    "    wp1::Vector{Float32}\n",
    "    wp2::Vector{Float32}\n",
    "    bp1::Vector{Float32}\n",
    "\n",
    "    wo1::Vector{Float32}\n",
    "    wo2::Vector{Float32}\n",
    "    bo1::Vector{Float32}\n",
    "\n",
    "\n",
    "    # cell state (aka. long-term memory) and hidden state (aka. short-term memory)\n",
    "    c::Vector{Float32}\n",
    "    h::Vector{Float32}\n",
    "\n",
    "    # prevents the model from modifying the memory state in case of testing and loss calculation\n",
    "    # it needs to be set explicitely before and after calling the model(x) funtion\n",
    "    update_memory::Bool\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the constructor\n",
    "LSTM(in::Integer, out::Integer) = LSTM(init_params(in, out)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overload call, so the object can be used as a function\n",
    "(lstm::LSTM)(x) = forward(x, lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a functor from the struct, so that the training can optimize its parameters\n",
    "Flux.@functor LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the Long Short-Term Memory layer\n",
    "function LSTM((in, out)::Pair)\n",
    "    LSTM(in, out) # constructor\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitely defining the trainable parameters of the layer\n",
    "# all the Wrights and Biases are trainable\n",
    "# exceptions >> Cell State and Hidden State\n",
    "# Flux.trainable(lstm::LSTM) = (lstm.Wf, lstm.Wi, lstm.Wc, lstm.Wo, lstm.bf, lstm.bi, lstm.bc, lstm.bo,)\n",
    "Flux.trainable(lstm::LSTM) = (lstm.wlr1, lstm.wlr2, lstm.blr1, lstm.wpr1, lstm.wpr2, lstm.bpr1, lstm.wp1, lstm.wp2, lstm.bp1, lstm.wo1, lstm.wo2, lstm.bo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random generating sequences\n",
    "num_sequences = 10_000\n",
    "num_selected_sequences = 1_000\n",
    "batch_size = div(size(parkinson, 1), num_sequences)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "input_size = batch_size\n",
    "hidden_size = 3\n",
    "num_classes = 4 \n",
    "\n",
    "model = Chain(\n",
    "    LSTM(input_size => hidden_size),\n",
    "    Dense(hidden_size => num_classes),\n",
    "    softmax\n",
    ")\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(x, y)\n",
    "    model[1].update_memory = false\n",
    "    l = Flux.crossentropy.(eachrow(model(x)'), eachrow(y'))\n",
    "    model[1].update_memory = true\n",
    "\n",
    "    mean(l)\n",
    "end\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 1 >> Loss: 1.1278929\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 2 >> Loss: 0.87639326\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 3 >> Loss: 0.7923002\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 4 >> Loss: 0.7449895\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 5 >> Loss: 0.72115785\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 6 >> Loss: 0.706191\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 7 >> Loss: 0.6969681\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 8 >> Loss: 0.6961485\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 9 >> Loss: 0.69098574\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 10 >> Loss: 0.68711144\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 11 >> Loss: 0.6888673\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 12 >> Loss: 0.685157\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 13 >> Loss: 0.6815091\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 14 >> Loss: 0.6846652\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 15 >> Loss: 0.6826887\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 16 >> Loss: 0.68496555\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 17 >> Loss: 0.68977225\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 18 >> Loss: 0.6878709\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 19 >> Loss: 0.6747157\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mEpoch: 20 >> Loss: 0.67317253\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in 1:epochs\n",
    "\n",
    "  epoch_loss = 0f0\n",
    "\n",
    "  for (input, output) in data_loader(parkinson_train, num_sequences, num_selected_sequences, batch_size)\n",
    "    grads = Flux.gradient(Flux.params(model)) do\n",
    "      l = loss(input, output) \n",
    "      epoch_loss += l\n",
    "\n",
    "      l\n",
    "    end\n",
    "    Flux.update!(optimizer, Flux.params(model), grads)\n",
    "  end\n",
    "\n",
    "  train_loss = epoch_loss / num_selected_sequences \n",
    "  @info \"Epoch: $epoch >> Loss: $train_loss\"\n",
    "  append!(losses, train_loss)\n",
    "\n",
    "\n",
    "  # TODO: Validation for epoch goes here\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip680\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip680)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip681\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip680)\" d=\"M156.02 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.02 47.2441  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip682\">\n    <rect x=\"156\" y=\"47\" width=\"2198\" height=\"1440\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"654.485,1486.45 654.485,47.2441 \"/>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1199.85,1486.45 1199.85,47.2441 \"/>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1745.22,1486.45 1745.22,47.2441 \"/>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2290.58,1486.45 2290.58,47.2441 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"156.02,1486.45 2352.76,1486.45 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"654.485,1486.45 654.485,1467.55 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1199.85,1486.45 1199.85,1467.55 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1745.22,1486.45 1745.22,1467.55 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2290.58,1486.45 2290.58,1467.55 \"/>\n<path clip-path=\"url(#clip680)\" d=\"M644.762 1514.29 L663.119 1514.29 L663.119 1518.22 L649.045 1518.22 L649.045 1526.7 Q650.063 1526.35 651.082 1526.19 Q652.1 1526 653.119 1526 Q658.906 1526 662.285 1529.17 Q665.665 1532.34 665.665 1537.76 Q665.665 1543.34 662.193 1546.44 Q658.721 1549.52 652.401 1549.52 Q650.225 1549.52 647.957 1549.15 Q645.711 1548.78 643.304 1548.04 L643.304 1543.34 Q645.387 1544.47 647.61 1545.03 Q649.832 1545.58 652.309 1545.58 Q656.313 1545.58 658.651 1543.48 Q660.989 1541.37 660.989 1537.76 Q660.989 1534.15 658.651 1532.04 Q656.313 1529.94 652.309 1529.94 Q650.434 1529.94 648.559 1530.35 Q646.707 1530.77 644.762 1531.65 L644.762 1514.29 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M1174.54 1544.91 L1182.18 1544.91 L1182.18 1518.55 L1173.87 1520.21 L1173.87 1515.95 L1182.13 1514.29 L1186.81 1514.29 L1186.81 1544.91 L1194.45 1544.91 L1194.45 1548.85 L1174.54 1548.85 L1174.54 1544.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M1213.89 1517.37 Q1210.28 1517.37 1208.45 1520.93 Q1206.65 1524.47 1206.65 1531.6 Q1206.65 1538.71 1208.45 1542.27 Q1210.28 1545.82 1213.89 1545.82 Q1217.52 1545.82 1219.33 1542.27 Q1221.16 1538.71 1221.16 1531.6 Q1221.16 1524.47 1219.33 1520.93 Q1217.52 1517.37 1213.89 1517.37 M1213.89 1513.66 Q1219.7 1513.66 1222.76 1518.27 Q1225.83 1522.85 1225.83 1531.6 Q1225.83 1540.33 1222.76 1544.94 Q1219.7 1549.52 1213.89 1549.52 Q1208.08 1549.52 1205 1544.94 Q1201.95 1540.33 1201.95 1531.6 Q1201.95 1522.85 1205 1518.27 Q1208.08 1513.66 1213.89 1513.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M1720.4 1544.91 L1728.04 1544.91 L1728.04 1518.55 L1719.73 1520.21 L1719.73 1515.95 L1728 1514.29 L1732.67 1514.29 L1732.67 1544.91 L1740.31 1544.91 L1740.31 1548.85 L1720.4 1548.85 L1720.4 1544.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M1749.8 1514.29 L1768.16 1514.29 L1768.16 1518.22 L1754.08 1518.22 L1754.08 1526.7 Q1755.1 1526.35 1756.12 1526.19 Q1757.14 1526 1758.16 1526 Q1763.94 1526 1767.32 1529.17 Q1770.7 1532.34 1770.7 1537.76 Q1770.7 1543.34 1767.23 1546.44 Q1763.76 1549.52 1757.44 1549.52 Q1755.26 1549.52 1753 1549.15 Q1750.75 1548.78 1748.34 1548.04 L1748.34 1543.34 Q1750.43 1544.47 1752.65 1545.03 Q1754.87 1545.58 1757.35 1545.58 Q1761.35 1545.58 1763.69 1543.48 Q1766.03 1541.37 1766.03 1537.76 Q1766.03 1534.15 1763.69 1532.04 Q1761.35 1529.94 1757.35 1529.94 Q1755.47 1529.94 1753.6 1530.35 Q1751.75 1530.77 1749.8 1531.65 L1749.8 1514.29 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M2269.36 1544.91 L2285.68 1544.91 L2285.68 1548.85 L2263.73 1548.85 L2263.73 1544.91 Q2266.39 1542.16 2270.98 1537.53 Q2275.58 1532.88 2276.76 1531.53 Q2279.01 1529.01 2279.89 1527.27 Q2280.79 1525.51 2280.79 1523.82 Q2280.79 1521.07 2278.85 1519.33 Q2276.93 1517.6 2273.82 1517.6 Q2271.63 1517.6 2269.17 1518.36 Q2266.74 1519.13 2263.96 1520.68 L2263.96 1515.95 Q2266.79 1514.82 2269.24 1514.24 Q2271.7 1513.66 2273.73 1513.66 Q2279.1 1513.66 2282.3 1516.35 Q2285.49 1519.03 2285.49 1523.52 Q2285.49 1525.65 2284.68 1527.57 Q2283.89 1529.47 2281.79 1532.07 Q2281.21 1532.74 2278.11 1535.95 Q2275.01 1539.15 2269.36 1544.91 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M2305.49 1517.37 Q2301.88 1517.37 2300.05 1520.93 Q2298.25 1524.47 2298.25 1531.6 Q2298.25 1538.71 2300.05 1542.27 Q2301.88 1545.82 2305.49 1545.82 Q2309.13 1545.82 2310.93 1542.27 Q2312.76 1538.71 2312.76 1531.6 Q2312.76 1524.47 2310.93 1520.93 Q2309.13 1517.37 2305.49 1517.37 M2305.49 1513.66 Q2311.3 1513.66 2314.36 1518.27 Q2317.44 1522.85 2317.44 1531.6 Q2317.44 1540.33 2314.36 1544.94 Q2311.3 1549.52 2305.49 1549.52 Q2299.68 1549.52 2296.6 1544.94 Q2293.55 1540.33 2293.55 1531.6 Q2293.55 1522.85 2296.6 1518.27 Q2299.68 1513.66 2305.49 1513.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"156.02,1365.61 2352.76,1365.61 \"/>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"156.02,1067.02 2352.76,1067.02 \"/>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"156.02,768.437 2352.76,768.437 \"/>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"156.02,469.849 2352.76,469.849 \"/>\n<polyline clip-path=\"url(#clip682)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"156.02,171.261 2352.76,171.261 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"156.02,1486.45 156.02,47.2441 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"156.02,1365.61 174.917,1365.61 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"156.02,1067.02 174.917,1067.02 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"156.02,768.437 174.917,768.437 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"156.02,469.849 174.917,469.849 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"156.02,171.261 174.917,171.261 \"/>\n<path clip-path=\"url(#clip680)\" d=\"M63.7467 1351.41 Q60.1356 1351.41 58.3069 1354.98 Q56.5014 1358.52 56.5014 1365.65 Q56.5014 1372.75 58.3069 1376.32 Q60.1356 1379.86 63.7467 1379.86 Q67.3809 1379.86 69.1865 1376.32 Q71.0152 1372.75 71.0152 1365.65 Q71.0152 1358.52 69.1865 1354.98 Q67.3809 1351.41 63.7467 1351.41 M63.7467 1347.71 Q69.5568 1347.71 72.6124 1352.31 Q75.6911 1356.9 75.6911 1365.65 Q75.6911 1374.37 72.6124 1378.98 Q69.5568 1383.56 63.7467 1383.56 Q57.9365 1383.56 54.8578 1378.98 Q51.8023 1374.37 51.8023 1365.65 Q51.8023 1356.9 54.8578 1352.31 Q57.9365 1347.71 63.7467 1347.71 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M83.9086 1377.01 L88.7928 1377.01 L88.7928 1382.89 L83.9086 1382.89 L83.9086 1377.01 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M97.7974 1348.33 L120.02 1348.33 L120.02 1350.32 L107.473 1382.89 L102.589 1382.89 L114.395 1352.27 L97.7974 1352.27 L97.7974 1348.33 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M62.9365 1052.82 Q59.3254 1052.82 57.4967 1056.39 Q55.6912 1059.93 55.6912 1067.06 Q55.6912 1074.17 57.4967 1077.73 Q59.3254 1081.27 62.9365 1081.27 Q66.5707 1081.27 68.3763 1077.73 Q70.205 1074.17 70.205 1067.06 Q70.205 1059.93 68.3763 1056.39 Q66.5707 1052.82 62.9365 1052.82 M62.9365 1049.12 Q68.7467 1049.12 71.8022 1053.73 Q74.8809 1058.31 74.8809 1067.06 Q74.8809 1075.79 71.8022 1080.39 Q68.7467 1084.98 62.9365 1084.98 Q57.1264 1084.98 54.0477 1080.39 Q50.9921 1075.79 50.9921 1067.06 Q50.9921 1058.31 54.0477 1053.73 Q57.1264 1049.12 62.9365 1049.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M83.0984 1078.42 L87.9827 1078.42 L87.9827 1084.3 L83.0984 1084.3 L83.0984 1078.42 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M108.168 1067.89 Q104.834 1067.89 102.913 1069.67 Q101.015 1071.46 101.015 1074.58 Q101.015 1077.71 102.913 1079.49 Q104.834 1081.27 108.168 1081.27 Q111.501 1081.27 113.422 1079.49 Q115.344 1077.68 115.344 1074.58 Q115.344 1071.46 113.422 1069.67 Q111.524 1067.89 108.168 1067.89 M103.492 1065.9 Q100.483 1065.16 98.7928 1063.1 Q97.1261 1061.04 97.1261 1058.08 Q97.1261 1053.93 100.066 1051.53 Q103.029 1049.12 108.168 1049.12 Q113.33 1049.12 116.27 1051.53 Q119.209 1053.93 119.209 1058.08 Q119.209 1061.04 117.52 1063.1 Q115.853 1065.16 112.867 1065.9 Q116.246 1066.69 118.121 1068.98 Q120.02 1071.27 120.02 1074.58 Q120.02 1079.61 116.941 1082.29 Q113.885 1084.98 108.168 1084.98 Q102.45 1084.98 99.3715 1082.29 Q96.316 1079.61 96.316 1074.58 Q96.316 1071.27 98.2141 1068.98 Q100.112 1066.69 103.492 1065.9 M101.779 1058.52 Q101.779 1061.2 103.446 1062.71 Q105.135 1064.21 108.168 1064.21 Q111.177 1064.21 112.867 1062.71 Q114.58 1061.2 114.58 1058.52 Q114.58 1055.83 112.867 1054.33 Q111.177 1052.82 108.168 1052.82 Q105.135 1052.82 103.446 1054.33 Q101.779 1055.83 101.779 1058.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M63.0291 754.235 Q59.418 754.235 57.5893 757.8 Q55.7838 761.342 55.7838 768.471 Q55.7838 775.578 57.5893 779.143 Q59.418 782.684 63.0291 782.684 Q66.6633 782.684 68.4689 779.143 Q70.2976 775.578 70.2976 768.471 Q70.2976 761.342 68.4689 757.8 Q66.6633 754.235 63.0291 754.235 M63.0291 750.532 Q68.8393 750.532 71.8948 755.138 Q74.9735 759.721 74.9735 768.471 Q74.9735 777.198 71.8948 781.805 Q68.8393 786.388 63.0291 786.388 Q57.2189 786.388 54.1403 781.805 Q51.0847 777.198 51.0847 768.471 Q51.0847 759.721 54.1403 755.138 Q57.2189 750.532 63.0291 750.532 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M83.191 779.837 L88.0753 779.837 L88.0753 785.717 L83.191 785.717 L83.191 779.837 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M98.3993 784.999 L98.3993 780.74 Q100.159 781.573 101.964 782.013 Q103.77 782.453 105.506 782.453 Q110.135 782.453 112.566 779.351 Q115.02 776.226 115.367 769.883 Q114.024 771.874 111.964 772.939 Q109.904 774.004 107.404 774.004 Q102.219 774.004 99.1863 770.879 Q96.1771 767.731 96.1771 762.291 Q96.1771 756.967 99.3252 753.749 Q102.473 750.532 107.705 750.532 Q113.7 750.532 116.848 755.138 Q120.02 759.721 120.02 768.471 Q120.02 776.643 116.131 781.527 Q112.265 786.388 105.714 786.388 Q103.955 786.388 102.149 786.041 Q100.344 785.693 98.3993 784.999 M107.705 770.346 Q110.853 770.346 112.682 768.193 Q114.533 766.041 114.533 762.291 Q114.533 758.564 112.682 756.411 Q110.853 754.235 107.705 754.235 Q104.557 754.235 102.705 756.411 Q100.876 758.564 100.876 762.291 Q100.876 766.041 102.705 768.193 Q104.557 770.346 107.705 770.346 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M53.6541 483.194 L61.293 483.194 L61.293 456.828 L52.9829 458.495 L52.9829 454.235 L61.2467 452.569 L65.9226 452.569 L65.9226 483.194 L73.5614 483.194 L73.5614 487.129 L53.6541 487.129 L53.6541 483.194 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M83.0058 481.249 L87.8901 481.249 L87.8901 487.129 L83.0058 487.129 L83.0058 481.249 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M108.075 455.647 Q104.464 455.647 102.635 459.212 Q100.83 462.754 100.83 469.883 Q100.83 476.99 102.635 480.555 Q104.464 484.096 108.075 484.096 Q111.709 484.096 113.515 480.555 Q115.344 476.99 115.344 469.883 Q115.344 462.754 113.515 459.212 Q111.709 455.647 108.075 455.647 M108.075 451.944 Q113.885 451.944 116.941 456.55 Q120.02 461.134 120.02 469.883 Q120.02 478.61 116.941 483.217 Q113.885 487.8 108.075 487.8 Q102.265 487.8 99.1863 483.217 Q96.1308 478.61 96.1308 469.883 Q96.1308 461.134 99.1863 456.55 Q102.265 451.944 108.075 451.944 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M54.881 184.606 L62.5198 184.606 L62.5198 158.24 L54.2097 159.907 L54.2097 155.648 L62.4735 153.981 L67.1494 153.981 L67.1494 184.606 L74.7883 184.606 L74.7883 188.541 L54.881 188.541 L54.881 184.606 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M84.2327 182.661 L89.1169 182.661 L89.1169 188.541 L84.2327 188.541 L84.2327 182.661 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M100.112 184.606 L107.751 184.606 L107.751 158.24 L99.4409 159.907 L99.4409 155.648 L107.705 153.981 L112.381 153.981 L112.381 184.606 L120.02 184.606 L120.02 188.541 L100.112 188.541 L100.112 184.606 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip682)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"218.191,87.9763 327.265,838.923 436.338,1090.01 545.411,1231.28 654.485,1302.44 763.558,1347.13 872.631,1374.67 981.704,1377.11 1090.78,1392.53 1199.85,1404.1 1308.92,1398.85 1418,1409.93 1527.07,1420.82 1636.14,1411.4 1745.22,1417.3 1854.29,1410.5 1963.36,1396.15 2072.44,1401.83 2181.51,1441.11 2290.58,1445.72 \"/>\n<path clip-path=\"url(#clip680)\" d=\"M2007.43 198.898 L2279.53 198.898 L2279.53 95.2176 L2007.43 95.2176  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2007.43,198.898 2279.53,198.898 2279.53,95.2176 2007.43,95.2176 2007.43,198.898 \"/>\n<polyline clip-path=\"url(#clip680)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2031.84,147.058 2178.28,147.058 \"/>\n<path clip-path=\"url(#clip680)\" d=\"M2216.54 166.745 Q2214.73 171.375 2213.02 172.787 Q2211.3 174.199 2208.43 174.199 L2205.03 174.199 L2205.03 170.634 L2207.53 170.634 Q2209.29 170.634 2210.26 169.8 Q2211.23 168.967 2212.42 165.865 L2213.18 163.921 L2202.69 138.412 L2207.21 138.412 L2215.31 158.689 L2223.41 138.412 L2227.92 138.412 L2216.54 166.745 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip680)\" d=\"M2235.22 160.402 L2242.85 160.402 L2242.85 134.037 L2234.54 135.703 L2234.54 131.444 L2242.81 129.778 L2247.48 129.778 L2247.48 160.402 L2255.12 160.402 L2255.12 164.338 L2235.22 164.338 L2235.22 160.402 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Plots.plot(collect(1:epochs), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@save \"LSTM.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@load \"LSTM.bson\" model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
