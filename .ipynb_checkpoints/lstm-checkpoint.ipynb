{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Long Short-Term Memory to detect and classify Parkinsons' Freezing of Gait types in time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "# Pkg.add(\"NNlib\")\n",
    "# Pkg.add(\"DataFrames\")\n",
    "# Pkg.add(\"ResumableFunctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: @epochs, batch, throttle\n",
    "\n",
    "using CSV\n",
    "using NNlib\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using ResumableFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinson = CSV.read(\"./filtered_data.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@resumable function data_loader(parkinson_dataframe, batch_size ; labels=[\"StartHesitation\", \"Turn\", \"Walking\", \"Normal\"])\n",
    "    pdf = deepcopy(parkinson_dataframe)\n",
    "\n",
    "    for i in 1:batch_size:size(pdf, 1)\n",
    "        if i > size(pdf, 1)\n",
    "            break\n",
    "        end\n",
    "        x = hcat(\n",
    "            pdf[!, \"AccV\"][i:i+batch_size],\n",
    "            pdf[!, \"AccML\"][i:i+batch_size],\n",
    "            pdf[!, \"AccAP\"][i:i+batch_size]\n",
    "        )\n",
    "    \n",
    "        y = Flux.onehotbatch(pdf[!, \"event\"][i:i+batch_size], labels)\n",
    "        \n",
    "        @yield x, y\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize weights with Gaussian distribution\n",
    "function init_params(in::Integer, out::Integer ; mean=0.0, std=1.0)\n",
    "    [\n",
    "        in, out,\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), (out, in)), # Wf\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), (out, in)), # Wi\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), (out, in)), # Wc\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), (out, in)), # Wo\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bf\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bi\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bc\n",
    "        rand(Truncated(Normal(mean, std), -1, 1), out), # bo\n",
    "\n",
    "        # both the Long-Term and Short-Term memories are initialized with 0 values\n",
    "        zeros(out, in), # c\n",
    "        zeros(out, in)  # h\n",
    "    ]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the forwarding method which is used in the Chaining process\n",
    "function forward(x, lstm)\n",
    "    @show \"FORWARD CALLED\"\n",
    "    # @assert typeof(lstm.Wf) == Matrix{Float64}\n",
    "    # @assert typeof(lstm.bf) == Vector{Float64}\n",
    "    \n",
    "    # calculating the Memory modifier values\n",
    "    f = NNlib.sigmoid_fast(lstm.Wf * x .+ lstm.bf) #\n",
    "    i = NNlib.sigmoid_fast(lstm.Wi * x .+ lstm.bi) #\n",
    "    o = NNlib.sigmoid_fast(lstm.Wo * x .+ lstm.bo) #\n",
    "\n",
    "    @show \"f-i-o was calculated\"\n",
    "\n",
    "    # calculating the new memory values\n",
    "    @show size(f)\n",
    "    @show size(lstm.c)\n",
    "    @show size(i)\n",
    "    @show size(lstm.Wc)\n",
    "    @show size(x)\n",
    "    @show size(lstm.bc)\n",
    "    @show size(NNlib.tanh_fast(lstm.Wc * x .+ lstm.bc))\n",
    "    c = f * lstm.c .+ i .* NNlib.tanh_fast(lstm.Wc * x .+ lstm.bc) # new Long-Term Memory\n",
    "\n",
    "    @show \"C calculated\"\n",
    "    @show size(o), size(c)\n",
    "    h = o .* NNlib.tanh_fast(c) # new Short-Term Memory\n",
    "\n",
    "    @show \"c-h was calculated\"\n",
    "\n",
    "    # updating the memory\n",
    "    lstm.c, lstm.h = c, h\n",
    "\n",
    "    @show \"memory was updated!\"\n",
    "\n",
    "    # returning the hidden parameters for the next layer\n",
    "    @show \"assert H\"\n",
    "    # @assert typeof(h) == Matrix{Float64}\n",
    "    @show size(h)\n",
    "    h\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom Long Short-Term Memory layer\n",
    "mutable struct LSTM\n",
    "    # input and output size of the layer\n",
    "    in::Integer\n",
    "    out::Integer\n",
    "\n",
    "    Wf::Matrix{Float64} # params of the Forget Gate\n",
    "    Wi::Matrix{Float64} # params of the Input Gate\n",
    "    Wc::Matrix{Float64} # params of the Input Modulation Gate\n",
    "    Wo::Matrix{Float64} # params of the Output Gate\n",
    "\n",
    "    # biases of the Gates above\n",
    "    bf::Vector{Float64}\n",
    "    bi::Vector{Float64}\n",
    "    bc::Vector{Float64}\n",
    "    bo::Vector{Float64}\n",
    "\n",
    "    # cell state (aka. long-term memory) and hidden state (aka. short-term memory)\n",
    "    c::Matrix{Float64}\n",
    "    h::Matrix{Float64}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the constructor\n",
    "LSTM(in::Integer, out::Integer) = LSTM(init_params(in, out)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overload call, so the object can be used as a function\n",
    "(lstm::LSTM)(x) = forward(x, lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a functor from the struct, so that the training can optimize its parameters\n",
    "Flux.@functor LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the Long Short-Term Memory layer\n",
    "function LSTM((in, out)::Pair)\n",
    "    LSTM(in, out) # constructor\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitely defining the trainable parameters of the layer\n",
    "# all the Wrights and Biases are trainable\n",
    "# exceptions >> Cell State and Hidden State\n",
    "Flux.trainable(lstm::LSTM) = (lstm.Wf, lstm.Wi, lstm.Wc, lstm.Wo, lstm.bf, lstm.bi, lstm.bc, lstm.bo,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "hidden_size = 3\n",
    "num_classes = 4 \n",
    "\n",
    "model = Chain(\n",
    "    LSTM(input_size => hidden_size),\n",
    "    Dense(hidden_size => num_classes),\n",
    "    softmax\n",
    ")\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.crossentropy(model(x), y)\n",
    "optimizer = ADAM(0.001)\n",
    "epochs = 10\n",
    "batch_size = 127 # data loader returns batch_size + 1 samples\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1:epochs\n",
    "  for (input, output) in data_loader(parkinson, batch_size)\n",
    "    grads = Flux.gradient(Flux.params(model)) do\n",
    "      loss(input, output)\n",
    "    end\n",
    "    Flux.update!(optimizer, Flux.params(model), grads)\n",
    "\n",
    "    break\n",
    "  end\n",
    "\n",
    "  break\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
