{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "# Pkg.add(\"NNlib\")\n",
    "# Pkg.add(\"DataFrames\")\n",
    "# Pkg.add(\"ResumableFunctions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mThis version of CUDA.jl only supports NVIDIA drivers for CUDA 11.x or higher (yours is for CUDA 9.1.0)\n",
      "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ CUDA C:\\Users\\hurub\\.julia\\packages\\CUDA\\s0e3j\\src\\initialization.jl:64\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using CSV\n",
    "using NNlib\n",
    "using Plots\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using ResumableFunctions\n",
    "\n",
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing a vector's values by applying moving average\n",
    "function moving_average(data; window_size = 100)\n",
    "    ma = []\n",
    "\n",
    "    for i = 1 : size(data, 1)\n",
    "        if i < window_size\n",
    "            append!(ma, [sum(data[1:i]) / i])\n",
    "        else\n",
    "            append!(ma, [sum(data[i-window_size+1:i]) / window_size])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    ma\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinson_data = CSV.read(\"./filtered_data.csv\", DataFrame)\n",
    "\n",
    "parkinson_copy = deepcopy(parkinson_data)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 40\n",
    "\n",
    "parkinson_copy[!, \"AccV\"]  = moving_average(parkinson_copy[!, \"AccV\"], window_size=window_size)\n",
    "parkinson_copy[!, \"AccML\"] = moving_average(parkinson_copy[!, \"AccML\"], window_size=window_size)\n",
    "parkinson_copy[!, \"AccAP\"] = moving_average(parkinson_copy[!, \"AccAP\"], window_size=window_size)\n",
    "\n",
    "# parkinson_copy\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plots.plot(collect(1:2000), parkinson_data[!, \"AccV\"][1:2000])\n",
    "Plots.plot!(p, collect(1:2000), parkinson_copy[!, \"AccV\"][1:2000])\n",
    "\n",
    "Plots.plot!(p, collect(1:2000), parkinson_data[!, \"AccML\"][1:2000])\n",
    "Plots.plot!(p, collect(1:2000), parkinson_copy[!, \"AccML\"][1:2000])\n",
    "\n",
    "Plots.plot!(p, collect(1:2000), parkinson_data[!, \"AccAP\"][1:2000])\n",
    "Plots.plot!(p, collect(1:2000), parkinson_copy[!, \"AccAP\"][1:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"./smoothed_filtered_data.csv\", parkinson_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@resumable function data_loader(parkinson_dataframe, batch_size ; labels=[\"StartHesitation\", \"Turn\", \"Walking\", \"Normal\"])\n",
    "    pdf = deepcopy(parkinson_dataframe)\n",
    "\n",
    "    for i in 1:batch_size:size(pdf, 1)\n",
    "        if i > size(pdf, 1)\n",
    "            break\n",
    "        end\n",
    "        x = hcat(\n",
    "            pdf[!, \"AccV\"][i:i+batch_size],\n",
    "            pdf[!, \"AccML\"][i:i+batch_size],\n",
    "            pdf[!, \"AccAP\"][i:i+batch_size]\n",
    "        )\n",
    "    \n",
    "        y = Flux.onehotbatch(pdf[!, \"event\"][i:i+batch_size], labels)\n",
    "        \n",
    "        @yield x, y\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y) in data_loader(parkinson_copy, 32)\n",
    "    @show x, y\n",
    "    break\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_params (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # initialize weights with Gaussian distribution\n",
    "function init_params(in::Integer, out::Integer ; mean=0.0, std=1.0)\n",
    "    [\n",
    "        in, out,\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (out, in)), # Wf\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (out, in)), # Wi\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (out, in)), # Wc\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), (out, in)), # Wo\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), out), # bf\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), out), # bi\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), out), # bc\n",
    "        rand(Truncated(Normal(mean, std), 0, 1), out), # bo\n",
    "\n",
    "        # both the Long-Term and Short-Term memories are initialized with 0 values\n",
    "        zeros(out), # c\n",
    "        zeros(out)  # h\n",
    "    ]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing the forwarding method which is used in the Chaining process\n",
    "function forward(x, lstm)\n",
    "    # calculating the Memory modifier values\n",
    "    f = NNlib.sigmoid_fast(lstm.Wf * x .+ lstm.bf) #\n",
    "    i = NNlib.sigmoid_fast(lstm.Wi * x .+ lstm.bi) #\n",
    "    o = NNlib.sigmoid_fast(lstm.Wo * x .+ lstm.bo) #\n",
    "\n",
    "    # calculating the new memory values\n",
    "    c = f .* lstm.c .+ i .* NNlib.tanh_fast(lstm.Wc * x .+ lstm.bc) # new Long-Term Memory\n",
    "    h = o .* NNlib.tanh_fast(c) # new Short-Term Memory\n",
    "\n",
    "    # updating the memory\n",
    "    lstm.c, lstm.h = c, h\n",
    "\n",
    "    # returning the hidden parameters for the next layer\n",
    "    h\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom Long Short-Term Memory layer\n",
    "mutable struct LSTM\n",
    "    # input and output size of the layer\n",
    "    in::Integer\n",
    "    out::Integer\n",
    "\n",
    "    Wf::AbstractMatrix # params of the Forget Gate\n",
    "    Wi::AbstractMatrix # params of the Input Gate\n",
    "    Wc::AbstractMatrix # params of the Input Modulation Gate\n",
    "    Wo::AbstractMatrix # params of the Output Gate\n",
    "\n",
    "    # biases of the Gates above\n",
    "    bf::AbstractVector\n",
    "    bi::AbstractVector\n",
    "    bc::AbstractVector\n",
    "    bo::AbstractVector\n",
    "\n",
    "    # cell state (aka. long-term memory) and hidden state (aka. short-term memory)\n",
    "    c::AbstractVector\n",
    "    h::AbstractVector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the constructor\n",
    "LSTM(in::Integer, out::Integer) = LSTM(init_params(in, out)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overload call, so the object can be used as a function\n",
    "(lstm::LSTM)(x) = forward(x, lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a functor from the struct, so that the training can optimize its parameters\n",
    "Flux.@functor LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the Long Short-Term Memory layer\n",
    "function LSTM((in, out)::Pair)\n",
    "    LSTM(in, out) # constructor\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitely defining the trainable parameters of the layer\n",
    "# all the Wrights and Biases are trainable\n",
    "# exceptions >> Cell State and Hidden State\n",
    "Flux.trainable(lstm::LSTM) = (lstm.Wf, lstm.Wi, lstm.Wc, lstm.Wo, lstm.bf, lstm.bi, lstm.bc, lstm.bo,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([[0.7287016229789081; 0.6659484378708097;;], [0.6489248524237079; 0.49765756180365056;;], [0.47029743932671625; 0.3272602733347646;;], [0.5466824529407139; 0.6382296846574739;;], [0.33792078551245835, 0.21388166310618117], [0.6565816767392486, 0.6831972269582973], [0.5001782461819304, 0.09487260329224652], [0.31957299010974316, 0.06945428263642425]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LSTM(1 => 2)\n",
    "\n",
    "Flux.params(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function LSTM((in, out)::Pair)\n",
    "#     # trainable parameters of the model\n",
    "#     Wf = rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)) # params of the Forget Gate\n",
    "#     Wi = rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)) # params of the Input Gate\n",
    "#     Wc = rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)) # params of the Input Modulation Gate\n",
    "#     Wo = rand(Truncated(Normal(mean, std), 0, 1), (hidden_size, input_size)) # params of the Output Gate\n",
    "\n",
    "#     # biases of the Gates above\n",
    "#     bf = rand(Truncated(Normal(mean, std), 0, 1), hidden_size)\n",
    "#     bi = rand(Truncated(Normal(mean, std), 0, 1), hidden_size)\n",
    "#     bc = rand(Truncated(Normal(mean, std), 0, 1), hidden_size)\n",
    "#     bo = rand(Truncated(Normal(mean, std), 0, 1), hidden_size)\n",
    "\n",
    "#     # cell state (aka. long-term memory) and hidden state (aka. short-term memory)\n",
    "#     c = zeros(out)\n",
    "#     h = zeros(out)\n",
    "\n",
    "#     x -> forward(x, params(Wf, Wi, Wc, Wo, bf, bi, bc, bo, c, h))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flux.@functor LSTM\n",
    "ltsm = x -> LTSM(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(1 => 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM(in::Integer, out::Integer) = LSTM(init_params(in, out)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m::LSTM)(x) = forward(m, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm(rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Flux.params(lstm)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "mutable struct CustomLSTM\n",
    "    Wf::Matrix\n",
    "    Wi::Matrix\n",
    "    Wc::Matrix\n",
    "    Wo::Matrix\n",
    "    bf::Vector\n",
    "    bi::Vector\n",
    "    bc::Vector\n",
    "    bo::Vector\n",
    "    h::Vector\n",
    "    c::Vector\n",
    "end\n",
    "\n",
    "function forward(lstm::CustomLSTM, x::Matrix)\n",
    "    batch_size, sequence_length = size(x)\n",
    "    hidden_size = size(lstm.h, 1)\n",
    "\n",
    "    h = lstm.h\n",
    "    c = lstm.c\n",
    "\n",
    "    h_out = Matrix{Float64}(undef, hidden_size, sequence_length)\n",
    "    c_out = Matrix{Float64}(undef, hidden_size, sequence_length)\n",
    "\n",
    "    for t in 1:sequence_length\n",
    "        # Extract the current input at time step t\n",
    "        x_t = x[:, t]\n",
    "\n",
    "        # LSTM Cell computations\n",
    "        f = σ.(lstm.Wf * x_t .+ lstm.bf .+ lstm.Wf * h .+ lstm.bf)\n",
    "        i = σ.(lstm.Wi * x_t .+ lstm.bi .+ lstm.Wi * h .+ lstm.bi)\n",
    "        c_tilde = tanh.(lstm.Wc * x_t .+ lstm.bc .+ lstm.Wc * h .+ lstm.bc)\n",
    "        c = f .* c + i .* c_tilde\n",
    "        o = σ.(lstm.Wo * x_t .+ lstm.bo .+ lstm.Wo * h .+ lstm.bo)\n",
    "        h = o .* tanh.(c)\n",
    "\n",
    "        h_out[:, t] = h\n",
    "        c_out[:, t] = c\n",
    "    end\n",
    "\n",
    "    lstm.h = h\n",
    "    lstm.c = c\n",
    "\n",
    "    return h_out, c_out\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
